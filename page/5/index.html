<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>H博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="编程博客">
<meta name="keywords" content="c++ java mysql shell linux h博客 android docker git laravel php python javascript python">
<meta property="og:type" content="website">
<meta property="og:title" content="H博客">
<meta property="og:url" content="https://blog.newtao.vip/page/5/index.html">
<meta property="og:site_name" content="H博客">
<meta property="og:description" content="编程博客">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="H博客">
<meta name="twitter:description" content="编程博客">
  
    <link rel="alternate" href="/atom.xml" title="H博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="/css/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<style>
.breathe-div {
    width: 200px;
    height: 200px;
    border: 1px solid #2b92d4;
    border-radius: 50%;
    text-align: center;
    cursor: pointer;
    margin:0px auto;
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.3);
    overflow: hidden;
    z-index: 10;
    -webkit-animation-timing-function: ease-in-out;
    -webkit-animation-name: breathe;
    -webkit-animation-duration: 1500ms;
    -webkit-animation-iteration-count: infinite;
    -webkit-animation-direction: alternate;
}

@-webkit-keyframes breathe {
    0% {
        opacity: .4;
        box-shadow: 0 1px 2px rgba(0, 147, 223, 0.4), 0 1px 1px rgba(0, 147, 223, 0.1) inset;
    }

    100% {
        opacity: 1;
        border: 1px solid rgba(59, 235, 235, 0.7);
        box-shadow: 0 1px 30px #0093df, 0 1px 20px #0093df inset;
    }
}
.breathe-point{position:absolute;left:50%; top:150px;}
.breathe-div{position:absolute;left:-100px; top:-100px }
</style>
<body>
  <div class="breathe-point">
  <div class="breathe-div"></div>
  </div>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">H博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">技术博客</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://blog.newtao.vip"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="true-autossh" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/24/autossh/" class="article-date">
  <time datetime="2019-12-24T01:13:04.453Z" itemprop="datePublished">2019-12-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/24/autossh/">autossh</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>autossh 是一个用来启动 ssh 并进行监控的程序，可在需要时重启 ssh，如果程序问题或者是网络问题。其灵感和机制来自于 rstunnel (Reliable SSH Tunnel). autossh 1.2 的方法已经改变：autossh 使用 ssh 来构造一个 ssh 重定向循环(本地到远程和远程到本地)，然后发送测试数据并获得返回结果。</p>
<p>内网主机主动连接到外网主机，又被称作反向连接(Reverse Connection)，这样NAT路由/防火墙就会在内网主机和外网主机之间建立映射即可相互通信了。但这种映射是路由网关自动维持的，不会持续下去，如果连接断开或者网络不稳定都会导致通信失败，这时内网主机需要自动重连机制了。</p>
<p>参数：</p>
<p>-M为autossh参数， -CqTfnN -D 为ssh参数<br>-M 5678 : 负责通过5678端口监视连接状态，连接有问题时就会自动重连<br>-C ：启动数据压缩传输<br>-q ：安静模式运行，忽略提示和错误<br>-T ：不占用shell<br>-f ：后台运行<br>-n ：配合 -f 参数使用<br>-N ：不执行远程命令，专为端口转发度身打造<br>-D 192.168.0.2:7070 ：指定一个本地机器 “动态的“ 应用程序端口转发，如果不加IP地址，默认只监听127.0.0.1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#将在&apos;x.x.x.x&apos;主机上开启一个本地侦听地址:18081,访问本地18081将转发至10.10.3.x:8080</span><br><span class="line"># autossh -M 9090 -fCNR 18081:10.10.3.x:8080 root@x.x.x.x</span><br></pre></td></tr></table></figure>

<p>隧道</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># autossh -M20000 -f -i ~/.ssh/id_rsa -Ng -D 7080 user@vps_host</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/24/autossh/" data-id="ckhlpbthb000fiu783ioczfvj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-kubernetes" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/21/kubernetes/" class="article-date">
  <time datetime="2019-12-21T07:29:00.115Z" itemprop="datePublished">2019-12-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Docker/">Docker</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/21/kubernetes/">kubernetes 国内 部署</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原文 <a href="https://www.cnblogs.com/tylerzhou/p/10971336.html" target="_blank" rel="noopener">https://www.cnblogs.com/tylerzhou/p/10971336.html</a></p>
<ol>
<li><p>修改主机名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#master节点:</span><br><span class="line">hostnamectl set-hostname node</span><br><span class="line">#node1节点：</span><br><span class="line">hostnamectl set-hostname node_1</span><br><span class="line">#node2节点:</span><br><span class="line">hostnamectl set-hostname node_2</span><br></pre></td></tr></table></figure>
</li>
<li><p>基本配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#修改/etc/hosts文件</span><br><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.*.100 k8s-master</span><br><span class="line">192.168.*.101 k8s-node1</span><br><span class="line">192.168.*.102 k8s-node2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#关闭防火墙和selinux</span><br><span class="line">systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">sed -i &apos;s/^SELINUX=enforcing$/SELINUX=disabled/&apos; /etc/selinux/config &amp;&amp; setenforce 0</span><br><span class="line"></span><br><span class="line">#关闭swap</span><br><span class="line">swapoff -a</span><br><span class="line">yes | cp /etc/fstab /etc/fstab_bak</span><br><span class="line">cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置时间同步<br>使用chrony同步时间，配置master节点与网络NTP服务器同步时间，所有node节点与master节点同步时间。</p>
</li>
</ol>
<p>配置master节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#安装chrony：</span><br><span class="line">yum install -y chrony</span><br><span class="line">#注释默认ntp服务器</span><br><span class="line">sed -i &apos;s/^server/#&amp;/&apos; /etc/chrony.conf</span><br><span class="line">#指定上游公共 ntp 服务器，并允许其他节点同步时间</span><br><span class="line">cat &gt;&gt; /etc/chrony.conf &lt;&lt; EOF</span><br><span class="line">server 0.asia.pool.ntp.org iburst</span><br><span class="line">server 1.asia.pool.ntp.org iburst</span><br><span class="line">server 2.asia.pool.ntp.org iburst</span><br><span class="line">server 3.asia.pool.ntp.org iburst</span><br><span class="line">allow all</span><br><span class="line">EOF</span><br><span class="line">#重启chronyd服务并设为开机启动：</span><br><span class="line">systemctl enable chronyd &amp;&amp; systemctl restart chronyd</span><br><span class="line">#开启网络时间同步功能</span><br><span class="line">timedatectl set-ntp true</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>配置所有node节点：<br>(注意修改master IP地址)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#安装chrony：</span><br><span class="line">yum install -y chrony</span><br><span class="line">#注释默认服务器</span><br><span class="line">sed -i &apos;s/^server/#&amp;/&apos; /etc/chrony.conf</span><br><span class="line">#指定内网 master节点为上游NTP服务器</span><br><span class="line">echo server 192.168.92.56 iburst &gt;&gt; /etc/chrony.conf</span><br><span class="line">#重启服务并设为开机启动：</span><br><span class="line">systemctl enable chronyd &amp;&amp; systemctl restart chronyd</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>所有节点执行chronyc sources命令，查看存在以^*开头的行，说明已经与服务器时间同步</p>
<p>修改iptables相关参数<br>RHEL / CentOS 7上的一些用户报告了由于iptables被绕过而导致流量路由不正确的问题。创建/etc/sysctl.d/k8s.conf文件，添加如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 使配置生效</span><br><span class="line">modprobe br_netfilter</span><br><span class="line">sysctl -p /etc/sysctl.d/k8s.conf</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>加载ipvs相关模块<br>由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块：<br>在所有的Kubernetes节点执行以下脚本:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line">#!/bin/bash</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#执行脚本</span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>上面脚本创建了/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。 使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块。<br>接下来还需要确保各个节点上已经安装了ipset软件包。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ipset ipvsadm -y</span><br></pre></td></tr></table></figure>

<ol start="6">
<li><p>安装Docker<br>Kubernetes默认的容器运行时仍然是Docker，使用的是kubelet中内置dockershim CRI实现。需要注意的是，Kubernetes 1.13最低支持的Docker版本是1.11.1，最高支持是18.06，而Docker最新版本已经是18.09了，故我们安装时需要指定版本为18.06.1-ce</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#配置docker yum源</span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line">#安装指定版本，这里安装18.06</span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line">yum install -y docker-ce-18.06.1.ce-3.el7</span><br><span class="line">systemctl start docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure>

<ul>
<li>安装kubeadm、kubelet、kubectl 官方安装文档可以参考：<a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a><br>1) kubelet 在群集中所有节点上运行的核心组件, 用来执行如启动pods和containers等操作。<br>2) ubeadm 引导启动k8s集群的命令行工具，用于初始化 Cluster。<br>3) kubectl 是 Kubernetes 命令行工具。通过 kubectl 可以部署和管理应用，查看各种资源，创建、删除和更新各种组件。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#配置kubernetes.repo的源，由于官方源国内无法访问，这里使用阿里云yum源</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#在所有节点上安装指定版本 kubelet、kubeadm 和 kubectl</span><br><span class="line">yum install -y kubelet-1.13.1 kubeadm-1.13.1 kubectl-1.13.1</span><br><span class="line"></span><br><span class="line">#启动kubelet服务</span><br><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>部署master节点<br>完整的官方文档可以参考：<br><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a><br><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/</a><br>Master节点执行初始化：<br>注意这里执行初始化用到了- -image-repository选项，指定初始化需要的镜像源从阿里云镜像仓库拉取。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">    --apiserver-advertise-address=192.168.92.56 \</span><br><span class="line">    --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">    --kubernetes-version v1.13.1 \</span><br><span class="line">    --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>初始化命令说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--apiserver-advertise-address</span><br></pre></td></tr></table></figure>

<p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--pod-network-cidr</span><br></pre></td></tr></table></figure>

<p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 –pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--image-repository</span><br></pre></td></tr></table></figure>

<p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--kubernetes-version=v1.13.1</span><br></pre></td></tr></table></figure>

<p>关闭版本探测，因为它的默认值是stable-1，会导致从<a href="https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.13.1）来跳过网络请求。" target="_blank" rel="noopener">https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.13.1）来跳过网络请求。</a><br>初始化过程如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">ght] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [192.168.92.56 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [192.168.92.56 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.92.56]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 21.009858 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.13&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;k8s-master&quot; as an annotation</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 60syk6.vnplamkn3zhwu3s3</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.92.56:6443 --token 60syk6.vnplamkn3zhwu3s3 --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]#</span><br></pre></td></tr></table></figure>

<p>(注意记录下初始化结果中的kubeadm join命令，部署worker节点时会用到)</p>
<p>初始化过程说明：</p>
<p>1) [preflight] kubeadm 执行初始化前的检查。<br>2) [kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml”<br>3) [certificates] 生成相关的各种token和证书<br>4) [kubeconfig] 生成 KubeConfig 文件，kubelet 需要这个文件与 Master 通信<br>5) [control-plane] 安装 Master 组件，会从指定的 Registry 下载组件的 Docker 镜像。<br>6) [bootstraptoken] 生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到<br>7) [addons] 安装附加组件 kube-proxy 和 kube-dns。<br>8) Kubernetes Master 初始化成功，提示如何配置常规用户使用kubectl访问集群。<br>9) 提示如何安装 Pod 网络。<br>10) 提示如何注册其他节点到 Cluster。</p>
<ol start="8">
<li>配置 kubectl<br>kubectl 是管理 Kubernetes Cluster 的命令行工具，前面我们已经在所有的节点安装了 kubectl。Master 初始化完成后需要做一些配置工作，然后 kubectl 就能使用了。<br>依照 kubeadm init 输出的最后提示，推荐用 Linux 普通用户执行 kubectl。<ul>
<li>创建普通用户centos<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#创建普通用户并设置密码123456</span><br><span class="line">useradd centos &amp;&amp; echo &quot;centos:123456&quot; | chpasswd centos</span><br><span class="line"></span><br><span class="line">#追加sudo权限,并配置sudo免密</span><br><span class="line">sed -i &apos;/^root/a\centos  ALL=(ALL)       NOPASSWD:ALL&apos; /etc/sudoers</span><br><span class="line"></span><br><span class="line">#保存集群安全配置文件到当前用户.kube目录</span><br><span class="line">su - centos</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">#启用 kubectl 命令自动补全功能（注销重新登录生效）</span><br><span class="line">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ol>
<p>需要这些配置命令的原因是：Kubernetes 集群默认需要加密方式访问。所以，这几条命令，就是将刚刚部署生成的 Kubernetes 集群的安全配置文件，保存到当前用户的.kube 目录下，kubectl 默认会使用这个目录下的授权信息访问 Kubernetes 集群。<br>如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置。<br>配置完成后centos用户就可以使用 kubectl 命令管理集群了。</p>
<p>查看集群状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get cs</span><br><span class="line">NAME STATUS MESSAGE ERROR</span><br><span class="line">scheduler Healthy ok</span><br><span class="line">controller-manager Healthy ok</span><br><span class="line">etcd-0 Healthy &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>确认各个组件都处于healthy状态。<br>查看节点状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get nodes</span><br><span class="line">NAME         STATUS     ROLES    AGE   VERSION</span><br><span class="line">k8s-master   NotReady   master   36m   v1.13.1</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>可以看到，当前只存在1个master节点，并且这个节点的状态是 NotReady。<br>使用 kubectl describe 命令来查看这个节点（Node）对象的详细信息、状态和事件（Event）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl describe node k8s-master</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                   Age                From                    Message</span><br><span class="line">  ----    ------                   ----               ----                    -------</span><br><span class="line">  Normal  Starting                 33m                kubelet, k8s-master     Starting kubelet.</span><br><span class="line">  Normal  NodeHasSufficientMemory  33m (x8 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasSufficientMemory</span><br><span class="line">  Normal  NodeHasNoDiskPressure    33m (x8 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasNoDiskPressure</span><br><span class="line">  Normal  NodeHasSufficientPID     33m (x7 over 33m)  kubelet, k8s-master     Node k8s-master status is now: NodeHasSufficientPID</span><br><span class="line">  Normal  NodeAllocatableEnforced  33m                kubelet, k8s-master     Updated Node Allocatable limit across pods</span><br><span class="line">  Normal  Starting                 33m                kube-proxy, k8s-master  Starting kube-proxy.</span><br></pre></td></tr></table></figure>

<p>通过 kubectl describe 指令的输出，我们可以看到 NodeNotReady 的原因在于，我们尚未部署任何网络插件，kube-proxy等组件还处于starting状态。<br>另外，我们还可以通过 kubectl 检查这个节点上各个系统 Pod 的状态，其中，kube-system 是 Kubernetes 项目预留的系统 Pod 的工作空间（Namepsace，注意它并不是 Linux Namespace，它只是 Kubernetes 划分不同工作空间的单位）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get pod -n kube-system -o wide</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-78d4cf999f-7jdx7             1/1     Running   0          11h   10.244.0.3      k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-78d4cf999f-s6mhk             1/1     Running   0          11h   10.244.0.2      k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-master                      1/1     Running   1          11h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   1          11h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   1          11h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-amd64-lkf2f          1/1     Running   0          10h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-przwf                     1/1     Running   1          11h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   1          11h   192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>可以看到，所有的系统 Pod 都成功启动了，而刚刚部署的flannel网络插件则在 kube-system 下面新建了一个名叫kube-flannel-ds-amd64-lkf2f的 Pod，一般来说，这些 Pod 就是容器网络插件在每个节点上的控制组件。<br>Kubernetes 支持容器网络插件，使用的是一个名叫 CNI 的通用接口，它也是当前容器网络的事实标准，市面上的所有容器网络开源项目都可以通过 CNI 接入 Kubernetes，比如 Flannel、Calico、Canal、Romana 等等，它们的部署方式也都是类似的“一键部署”。<br>再次查看master节点状态已经为ready状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   11h   v1.13.1</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>至此，Kubernetes 的 Master 节点就部署完成了。如果你只需要一个单节点的 Kubernetes，现在你就可以使用了。不过，在默认情况下，Kubernetes 的 Master 节点是不能运行用户 Pod 的。</p>
<ol start="10">
<li>部署worker节点</li>
</ol>
<p>Kubernetes 的 Worker 节点跟 Master 节点几乎是相同的，它们运行着的都是一个 kubelet 组件。唯一的区别在于，在 kubeadm init 的过程中，kubelet 启动后，Master 节点上还会自动运行 kube-apiserver、kube-scheduler、kube-controller-manger 这三个系统 Pod。<br>在 k8s-node1 和 k8s-node2 上分别执行如下命令，将其注册到 Cluster 中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#执行以下命令将节点接入集群</span><br><span class="line">kubeadm join 192.168.92.56:6443 --token 67kq55.8hxoga556caxty7s --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span><br><span class="line"></span><br><span class="line">#如果执行kubeadm init时没有记录下加入集群的命令，可以通过以下命令重新创建</span><br><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure>

<p>在k8s-node1上执行kubeadm join ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@k8s-node1 ~]# kubeadm join 192.168.92.56:6443 --token 67kq55.8hxoga556caxty7s --discovery-token-ca-cert-hash sha256:7d50e704bbfe69661e37c5f3ad13b1b88032b6b2b703ebd4899e259477b5be69</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[discovery] Trying to connect to API Server &quot;192.168.92.56:6443&quot;</span><br><span class="line">[discovery] Created cluster-info discovery client, requesting info from &quot;https://192.168.92.56:6443&quot;</span><br><span class="line">[discovery] Requesting info from &quot;https://192.168.92.56:6443&quot; again to validate TLS against the pinned public key</span><br><span class="line">[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;192.168.92.56:6443&quot;</span><br><span class="line">[discovery] Successfully established connection with API Server &quot;192.168.92.56:6443&quot;</span><br><span class="line">[join] Reading configuration from the cluster...</span><br><span class="line">[join] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.13&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;k8s-node1&quot; as an annotation</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the master to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">[root@k8s-node1 ~]#</span><br></pre></td></tr></table></figure>

<p>重复执行以上操作将k8s-node2也加进去（注意重新执行kubeadm token create –print-join-command）。<br>然后根据提示，我们可以通过 kubectl get nodes 查看节点的状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES    AGE    VERSION</span><br><span class="line">k8s-master   Ready    master   11h    v1.13.1</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   24m    v1.13.1</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   4m9s   v1.13.1</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>nodes状态全部为ready，由于每个节点都需要启动若干组件，如果node节点的状态是 NotReady，可以查看所有节点pod状态，确保所有pod成功拉取到镜像并处于running状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   coredns-78d4cf999f-7jdx7             1/1     Running   0          11h     10.244.0.3      k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-78d4cf999f-s6mhk             1/1     Running   0          11h     10.244.0.2      k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   1          12h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   1          12h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   1          12h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-d2r8p          1/1     Running   0          6m43s   192.168.92.58   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-d85c6          1/1     Running   0          27m     192.168.92.57   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-lkf2f          1/1     Running   0          11h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-k8jx8                     1/1     Running   0          6m43s   192.168.92.58   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-n95ck                     1/1     Running   0          27m     192.168.92.57   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-przwf                     1/1     Running   1          12h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   1          12h     192.168.92.56   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>这时，所有的节点都已经 Ready，Kubernetes Cluster 创建成功，一切准备就绪。<br>如果pod状态为Pending、ContainerCreating、ImagePullBackOff 都表明 Pod 没有就绪，Running 才是就绪状态。<br>如果有pod提示Init:ImagePullBackOff，说明这个pod的镜像在对应节点上拉取失败，我们可以通过 kubectl describe pod 查看 Pod 具体情况，以确认拉取失败的镜像：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl describe pod kube-flannel-ds-amd64-d2r8p --namespace=kube-system</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                 From                Message</span><br><span class="line">  ----     ------     ----                ----                -------</span><br><span class="line">  Normal   Scheduled  2m14s               default-scheduler   Successfully assigned kube-system/kube-flannel-ds-amd64-lzx5v to k8s-node2</span><br><span class="line">  Warning  Failed     109s                kubelet, k8s-node2  Failed to pull image &quot;quay.io/coreos/flannel:v0.10.0-amd64&quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://quay.io/v2/: net/http: TLS handshake timeout</span><br><span class="line">  Warning  Failed     109s                kubelet, k8s-node2  Error: ErrImagePull</span><br><span class="line">  Normal   BackOff    108s                kubelet, k8s-node2  Back-off pulling image &quot;quay.io/coreos/flannel:v0.10.0-amd64&quot;</span><br><span class="line">  Warning  Failed     108s                kubelet, k8s-node2  Error: ImagePullBackOff</span><br><span class="line">  Normal   Pulling    94s (x2 over 2m6s)  kubelet, k8s-node2  pulling image &quot;quay.io/coreos/flannel:v0.10.0-amd64&quot;</span><br></pre></td></tr></table></figure>

<p>这里看最后events输出内容，可以看到在下载 image 时失败，如果网络质量不好，这种情况是很常见的。我们可以耐心等待，因为 Kubernetes 会重试，我们也可以自己手工执行 docker pull 去下载这个镜像。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node2 ~]# docker pull quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">v0.10.0-amd64: Pulling from coreos/flannel</span><br><span class="line">ff3a5c916c92: Already exists</span><br><span class="line">8a8433d1d437: Already exists</span><br><span class="line">306dc0ee491a: Already exists</span><br><span class="line">856cbd0b7b9c: Already exists</span><br><span class="line">af6d1e4decc6: Already exists</span><br><span class="line">Digest: sha256:88f2b4d96fae34bfff3d46293f7f18d1f9f3ca026b4a4d288f28347fcb6580ac</span><br><span class="line">Status: Image is up to date for quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">[root@k8s-node2 ~]#</span><br></pre></td></tr></table></figure>

<p>如果无法从 quay.io/coreos/flannel:v0.10.0-amd64 下载镜像，可以从阿里云或者dockerhub镜像仓库下载，然后改回原来的tag即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64 quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/kubernetes_containers/flannel:v0.10.0-amd64</span><br></pre></td></tr></table></figure>

<p>查看master节点下载了哪些镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ sudo docker images</span><br><span class="line">REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-proxy                v1.13.1             fdb321fd30a0        2 weeks ago         80.2MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-apiserver            v1.13.1             40a63db91ef8        2 weeks ago         181MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-scheduler            v1.13.1             ab81d7360408        2 weeks ago         79.6MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-controller-manager   v1.13.1             26e6f1db2a52        2 weeks ago         146MB</span><br><span class="line">registry.aliyuncs.com/google_containers/coredns                   1.2.6               f59dcacceff4        8 weeks ago         40MB</span><br><span class="line">registry.aliyuncs.com/google_containers/etcd                      3.2.24              3cab8e1b9802        3 months ago        220MB</span><br><span class="line">quay.io/coreos/flannel                                            v0.10.0-amd64       f0fad859c909        11 months ago       44.6MB</span><br><span class="line">registry.aliyuncs.com/google_containers/pause                     3.1                 da86e6ba6ca1        12 months ago       742kB</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>查看node节点下载了哪些镜像：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]# docker images</span><br><span class="line">REPOSITORY                                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-proxy   v1.13.1             fdb321fd30a0        2 weeks ago         80.2MB</span><br><span class="line">quay.io/coreos/flannel                               v0.10.0-amd64       f0fad859c909        11 months ago       44.6MB</span><br><span class="line">registry.aliyuncs.com/google_containers/pause        3.1                 da86e6ba6ca1        12 months ago       742kB</span><br><span class="line">[root@k8s-node1 ~]#</span><br></pre></td></tr></table></figure>

<p>测试集群各个组件<br>首先验证kube-apiserver, kube-controller-manager, kube-scheduler, pod network 是否正常：<br>部署一个 Nginx Deployment，包含2个Pod<br>参考：<a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl create deployment nginx --image=nginx:alpine</span><br><span class="line">deployment.apps/nginx created</span><br><span class="line">[centos@k8s-master ~]$ kubectl scale deployment nginx --replicas=2</span><br><span class="line">deployment.extensions/nginx scaled</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>验证Nginx Pod是否正确运行，并且会分配10.244.开头的集群IP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get pods -l app=nginx -o wide</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-54458cd494-p2qgx   1/1     Running   0          111s   10.244.1.2   k8s-node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-54458cd494-sdlm7   1/1     Running   0          103s   10.244.2.2   k8s-node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>再验证一下kube-proxy是否正常：</p>
<p>以 NodePort 方式对外提供服务<br>参考：<a href="https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">service/nginx exposed</span><br><span class="line">[centos@k8s-master ~]$ kubectl get services nginx</span><br><span class="line">NAME    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">nginx   NodePort   10.108.17.2   &lt;none&gt;        80:30670/TCP   12s</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>可以通过任意 NodeIP:Port 在集群外部访问这个服务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ curl 192.168.92.56:30670</span><br><span class="line">[centos@k8s-master ~]$ curl 192.168.92.57:30670</span><br><span class="line">[centos@k8s-master ~]$ curl 192.168.92.58:30670</span><br></pre></td></tr></table></figure>

<p>访问k8s-master ip</p>
<p>最后验证一下dns, pod network是否正常：<br>运行Busybox并进入交互模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl run -it curl --image=radial/busyboxplus:curl</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">If you don&apos;t see a command prompt, try pressing enter.</span><br><span class="line">[ root@curl-66959f6557-s5qqs:/ ]$</span><br></pre></td></tr></table></figure>

<p>输入nslookup nginx查看是否可以正确解析出集群内的IP，以验证DNS是否正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ root@curl-66959f6557-s5qqs:/ ]$ nslookup nginx</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      nginx</span><br><span class="line">Address 1: 10.108.17.2 nginx.default.svc.cluster.local</span><br></pre></td></tr></table></figure>

<p>通过服务名进行访问，验证kube-proxy是否正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[ root@curl-66959f6557-q472z:/ ]$ curl http://nginx/</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">......</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">[ root@curl-66959f6557-q472z:/ ]$</span><br></pre></td></tr></table></figure>

<p>分别访问一下2个Pod的内网IP，验证跨Node的网络通信是否正常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[ root@curl-66959f6557-s5qqs:/ ]$ curl 10.244.1.2</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">......</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">[ root@curl-66959f6557-s5qqs:/ ]$ curl 10.244.2.2</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">......</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">[ root@curl-66959f6557-s5qqs:/ ]$</span><br></pre></td></tr></table></figure>

<p>Pod调度到Master节点<br>出于安全考虑，默认配置下Kubernetes不会将Pod调度到Master节点。查看Taints字段默认配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl describe node k8s-master</span><br><span class="line">......</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br></pre></td></tr></table></figure>

<p>如果希望将k8s-master也当作Node节点使用，可以执行如下命令,其中k8s-master是主机节点hostname：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8s-master node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure>

<p>修改后Taints字段状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl describe node k8s-master</span><br><span class="line">......</span><br><span class="line">Taints:             &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>如果要恢复Master Only状态，执行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8s-master node-role.kubernetes.io/master=:NoSchedule</span><br></pre></td></tr></table></figure>

<p>kube-proxy开启ipvs<br>修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: “ipvs”：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl edit cm kube-proxy -n kube-system</span><br><span class="line">configmap/kube-proxy edited</span><br></pre></td></tr></table></figure>

<p>之后重启各个节点上的kube-proxy pod：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl get pod -n kube-system | grep kube-proxy | awk &apos;&#123;system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)&#125;&apos;</span><br><span class="line">pod &quot;kube-proxy-2w9sh&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-gw4lx&quot; deleted</span><br><span class="line">pod &quot;kube-proxy-thv4c&quot; deleted</span><br><span class="line">[centos@k8s-master ~]$ kubectl get pod -n kube-system | grep kube-proxy</span><br><span class="line">kube-proxy-6qlgv                        1/1     Running   0          65s</span><br><span class="line">kube-proxy-fdtjd                        1/1     Running   0          47s</span><br><span class="line">kube-proxy-m8zkx                        1/1     Running   0          52s</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>查看日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[centos@k8s-master ~]$ kubectl logs kube-proxy-6qlgv -n kube-system</span><br><span class="line">I1213 09:50:15.414493       1 server_others.go:189] Using ipvs Proxier.</span><br><span class="line">W1213 09:50:15.414908       1 proxier.go:365] IPVS scheduler not specified, use rr by default</span><br><span class="line">I1213 09:50:15.415021       1 server_others.go:216] Tearing down inactive rules.</span><br><span class="line">I1213 09:50:15.461658       1 server.go:464] Version: v1.13.0</span><br><span class="line">I1213 09:50:15.467827       1 conntrack.go:52] Setting nf_conntrack_max to 131072</span><br><span class="line">I1213 09:50:15.467997       1 config.go:202] Starting service config controller</span><br><span class="line">I1213 09:50:15.468010       1 controller_utils.go:1027] Waiting for caches to sync for service config controller</span><br><span class="line">I1213 09:50:15.468092       1 config.go:102] Starting endpoints config controller</span><br><span class="line">I1213 09:50:15.468100       1 controller_utils.go:1027] Waiting for caches to sync for endpoints config controller</span><br><span class="line">I1213 09:50:15.568766       1 controller_utils.go:1034] Caches are synced for endpoints config controller</span><br><span class="line">I1213 09:50:15.568950       1 controller_utils.go:1034] Caches are synced for service config controller</span><br><span class="line">[centos@k8s-master ~]$</span><br></pre></td></tr></table></figure>

<p>日志中打印出了Using ipvs Proxier，说明ipvs模式已经开启。</p>
<p>移除节点和集群<br>kubernetes集群移除节点<br>以移除k8s-node2节点为例，在Master节点上运行：<br>kubectl drain k8s-node2 –delete-local-data –force –ignore-daemonsets<br>kubectl delete node k8s-node2<br>上面两条命令执行完成后，在k8s-node2节点执行清理命令，重置kubeadm的安装状态：<br>kubeadm reset<br>在master上删除node并不会清理k8s-node2运行的容器，需要在删除节点上面手动运行清理命令。<br>如果你想重新配置集群，使用新的参数重新运行kubeadm init或者kubeadm join即可。</p>
<p>至此3个节点的集群搭建完成，后续可以继续添加node节点，或者部署dashboard、helm包管理工具、EFK日志系统、Prometheus Operator监控系统、rook+ceph存储系统等组件。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/21/kubernetes/" data-id="ckhlpbtkb0021iu78y3ejfm15" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-terminal_proxy" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/21/terminal_proxy/" class="article-date">
  <time datetime="2019-12-21T01:18:38.059Z" itemprop="datePublished">2019-12-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/21/terminal_proxy/">让终端走socks5代理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p>把代理服务器地址写入shell配置文件.bashrc或者.zshrc<br>直接在.bashrc或者.zshrc添加下面内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export http_proxy=&quot;http://localhost:port&quot;</span><br><span class="line">export https_proxy=&quot;http://localhost:port&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>shadowsocks代理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export http_proxy=&quot;socks5://127.0.0.1:1080&quot;</span><br><span class="line">export https_proxy=&quot;socks5://127.0.0.1:1080&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>ALL_PROXY</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alias setproxy=&quot;export ALL_PROXY=socks5://127.0.0.1:1080&quot;</span><br><span class="line">alias unsetproxy=&quot;unset ALL_PROXY&quot;</span><br></pre></td></tr></table></figure>

</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/21/terminal_proxy/" data-id="ckhlpbtol004ciu78ginsu46s" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-grep" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/20/grep/" class="article-date">
  <time datetime="2019-12-20T03:18:45.660Z" itemprop="datePublished">2019-12-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/20/grep/">grep</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p>IP 简单匹配</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -E -o &quot;([0-9]&#123;1,3&#125;[\.])&#123;3&#125;[0-9]&#123;1,3&#125;&quot; file</span><br></pre></td></tr></table></figure>
</li>
<li><p>-E选项表示使用grep扩展的正则表达式 -o选项是只显示匹配到的字符串 </p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/20/grep/" data-id="ckhlpbtj00018iu78ez9auzro" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-ssh2_msg_kexinit" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/19/ssh2_msg_kexinit/" class="article-date">
  <time datetime="2019-12-19T06:25:51.667Z" itemprop="datePublished">2019-12-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/19/ssh2_msg_kexinit/">SSH卡</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>ssh卡在debug1: SSH2_MSG_KEXINIT sent解决方法</li>
</ol>
<p>现象：主机间互通正常且可以判断对方ssh端口是开放的，但是用ssh xxx.xxx.xxx.xxx -v这种方式连接的时候会卡在debug1: SSH2_MSG_KEXINIT sent这步</p>
<p>解决方法：echo “1454” &gt; /sys/class/net/eth0/mtu</p>
<p>原因：详情参考<a href="http://techbackground.blogspot.com/2013/06/path-mtu-discovery-and-gre.html" target="_blank" rel="noopener">http://techbackground.blogspot.com/2013/06/path-mtu-discovery-and-gre.html</a>   简单解释就是IPV4报头与GRE报头结构不同，导致GRE数据包最大内容载荷只有1454，默认mtu如果是1500的话，就会有46字节的内容无法处理导致错误</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/19/ssh2_msg_kexinit/" data-id="ckhlpbtnu0040iu78ddqq0xsi" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-linux_date" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/06/linux_date/" class="article-date">
  <time datetime="2019-12-06T06:46:16.814Z" itemprop="datePublished">2019-12-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/06/linux_date/">Date</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1.从时间服务器更新时间</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate -u ntp.api.bz</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/06/linux_date/" data-id="ckhlpbtjy001riu78dowewh6h" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-find" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/06/find/" class="article-date">
  <time datetime="2019-12-06T06:18:23.198Z" itemprop="datePublished">2019-12-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/shell/">shell</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/06/find/">Linux</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>find<br>-mtime n[smhdw]<br>             If no units are specified, this primary evaluates to true if the difference between the file last modification time and the time find was started, rounded up to the next full 24-hour period, is n 24-hour periods.</p>
<pre><code>If units are specified, this primary evaluates to true if the difference between the file last modification time and the time find was started is exactly n units.  Please refer to the -atime primary description for information on
supported time units.</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find -mtime +1 -type file</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/12/06/find/" data-id="ckhlpbthx000tiu782o60ox1i" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-iostat" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/22/iostat/" class="article-date">
  <time datetime="2019-11-22T05:27:41.322Z" itemprop="datePublished">2019-11-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/22/iostat/">iostat</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1.常用命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iostat -d -k 1 10</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/11/22/iostat/" data-id="ckhlpbtk4001wiu78p22qgo8f" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-mongo" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/21/mongo/" class="article-date">
  <time datetime="2019-11-21T06:30:42.469Z" itemprop="datePublished">2019-11-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/PHP/">PHP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/21/mongo/">宝塔环境 mongodb php拓展</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li><p><a href="https://pecl.php.net/package/mongodb" target="_blank" rel="noopener">https://pecl.php.net/package/mongodb</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://pecl.php.net/get/mongodb-1.6.0.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>解压和编译安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf mongodb-1.6.0.tgz</span><br><span class="line">cd mongodb-1.6.0</span><br><span class="line">/www/server/php/72/bin/phpize </span><br><span class="line">./configure --with-php-config=/www/server/php/72/bin/php-config</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/11/21/mongo/" data-id="ckhlpbtkh0026iu78o026x73w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="true-vim" class="article article-type-true" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/20/vim/" class="article-date">
  <time datetime="2019-11-20T03:47:31.312Z" itemprop="datePublished">2019-11-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/20/vim/">Vim</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>.vimrc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set tabstop=4</span><br><span class="line">set softtabstop=4</span><br><span class="line">set shiftwidth=4</span><br><span class="line">set expandtab</span><br><span class="line">set autoindent</span><br><span class="line">set cindent</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="https://blog.newtao.vip/2019/11/20/vim/" data-id="ckhlpbtou004hiu78a0uvjq35" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/6/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CTF/">CTF</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GIT/">GIT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mac/">Mac</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/中间件/">中间件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/交易所/">交易所</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/区块链/">区块链</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/后端/">后端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/微服务/">微服务</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/汇编/">汇编</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/源码/">源码</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络安全/">网络安全</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/阿里云/">阿里云</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/29/sshd_ip/">防火墙ssh白名单</a>
          </li>
        
          <li>
            <a href="/2020/07/15/aliyun_disk/">磁盘扩容</a>
          </li>
        
          <li>
            <a href="/2020/07/10/wget_c/">wget</a>
          </li>
        
          <li>
            <a href="/2020/07/08/ctf/">安全领域资源</a>
          </li>
        
          <li>
            <a href="/2020/07/08/asm/">汇编指令集</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 anonymous<br>
      Powered by <a href="https://baike.baidu.com/item/%E5%8C%BF%E5%90%8D%E8%80%85%E9%BB%91%E5%AE%A2%E7%BB%84%E7%BB%87/8378313?fromtitle=Anonymous&fromid=7157039&fr=aladdin" target="_blank">H</a>
      <a href="http://beian.miit.gov.cn">鲁ICP备18014570号</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  </div>
    <!-- waifu-tips.js 依赖 JQuery 库 -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <!-- 实现拖动效果，需引入 JQuery UI -->
    <script src="https://cdn.jsdelivr.net/npm/jquery-ui-dist@1.12.1/jquery-ui.min.js"></script>
    <script src="images/assets/autoload.js?v=1.4.2"></script>
</body>
</html>
